<h1>
 Title: Do Bad Comments End a Conversation? - Reflection Post
</h1>
<h3>
 Author: Linda Wang (student)
</h3>
<h3>
 Date: 2021-09-22T11:11:47.484466+10:00
</h3>
<h3>
 Category: A1_reflection
</h3>
<h3>
 Vote Count: 0
</h3>
<p>
 Attached is our slide deck for the reflection post.
</p>
<a href="https://static.us.edusercontent.com/files/GftbmPYPTa5j1Haw7IEmMN6k">
 AI Presentation.pptx
</a>
<h3>
 ----------- REPLIES -----------
</h3>
<div style="text-indent: 2em;">
 <h3>
  Author: Fede Bologna (she/her) (student)
 </h3>
 <h3>
  Vote Count: 0
 </h3>
 <p>
  Hi Celine, Linda and Kowe! Thank you for your project. I found it compelling because it investigates an often overlooked platform and ties back to our class’ readings, providing new insights into negative behaviour online. I particularly appreciate the project’s scope, as it has clear implications for the debate regarding moderation practices in only forums. It raises the question: if bad comments don’t lead to a conversation ending, what’s the role of moderation online?
 </p>
 <p>
  As you mention in the “Future work” section, a clear next step for this project would be to divide flame-bait and troll comments from redundant and off-topic ones, and to separately analyze these two groups. Specifically, it would be interesting to:
 </p>
 <list style="ordered">
  <li>
   <p>
    Analyze how linguistically different these categories of bad comments actually are from each other. In class, many of us questioned what made flame-bait and troll comments different from each other. One way to do this would be comparing log-odd ratios calculated on the two samples.
   </p>
  </li>
  <li>
   <p>
    Analyze what makes these categories of bad comments different from each other. This could be investigated using the argument-only features in table 3 in Chenhao et al. “"Winning arguments: Interaction dynamics and persuasion strategies in good-faith online discussions." (2016). These features are especially useful in capturing linguistic style. Topic distributions extracted using LDA topic modeling could be added to this group of features.
   </p>
  </li>
  <li>
   <p>
    Investigate the relationship between bad comments and previous or following comments using the interplay features in table 2 in Chenhao et al., “"Winning arguments: Interaction dynamics and persuasion strategies in good-faith online discussions." (2016). A different but similarly effective approach would be to employ the linguist coordination measure explained in Danescu-Niculescu-Mizil et al., “Echoes of Power: Language Effects and Power Differences in Social Interaction” (2012).
   </p>
  </li>
  <li>
   <p>
    Investigate the relationship between authors of bad comments and the authors of previous or following comments - one of the social factors mentioned by Hovy and Yang, “The Importance of Modeling Social Factors of Language: Theory and Practice“ (2021). Analyzing network patterns using network theory could reveal patterns of flame-baiting and trolling attitudes - and harassment? - between users online.
   </p>
  </li>
 </list>
 <p>
  I apologize for the many suggestions - this object of study is just so interesting! Let me know what you think!
 </p>
 <h3>
  ------------------------------------
 </h3>
 <div style="text-indent: 2em;">
  <h3>
   Author: Celine Lee (student)
  </h3>
  <h3>
   Vote Count: 0
  </h3>
  <list style="ordered">
  </list>
  <p>
   A1 gave me the opportunity to examine data and come up with a question of interest without knowing whether that question was something that we could even answer using the data we have.
  </p>
  <p>
   I have two primary lessons to pass on from this A1 experience. First, data extraction should be a non-static, flexible process. This is because over the course of exploring and generating statistics over the data space, we are likely to run into more questions than answers. Then we would want our data extraction process to be relatively easy to modify so that we can go back and extract more or re-process different configurations of the data. The nature of this pilot study seems iterative, so the processes used in this pilot study should also be iterable. The second lesson I would share is to be willing/able to cut exploration of certain questions. In other words, as more questions arise over the course of exploration, somebody doing this pilot study should be able to evaluate which questions they should prioritize and spend more time on, and which questions they do not have the scope to pursue in the scope of the project. My team came up with dozens of ideas for information we wanted to compile from the Slashdot data, but we had to eventually stop pursuing some of them because our lines of inquiry were diverging from each other.
  </p>
  <p>
   One thing I am particularly proud of is the teamwork my group had over the course of this project. Specifically, I am impressed with our ability to use periodic meetings to corral our research questions. We met every few days to discuss findings we had made since the last meeting, notes that we shared with one another in our shared drive, questions that arose from our findings, how our questions related to or were essentially identical to one anothers', and how to connect our intermediate findings to decide what to do next.
  </p>
  <p>
   I ended up spending most of my time on the front and latter end of the project: writing the scripts to preprocess the Slashdot data, and wrapping my head around our final findings to try to connect them into some cohesive picture.
  </p>
  <h3>
   ------------------------------------
  </h3>
  <div style="text-indent: 4em;">
   <h3>
    Author: Linda Wang (student)
   </h3>
   <h3>
    Vote Count: 0
   </h3>
   <p>
    Lessons:
   </p>
   <p>
    I learned a lot from working on A1 with Kowe and Celine, and I have two main takeaways from the experience. Firstly, it’s best to be open-minded when analyzing a new dataset. (I hadn’t heard of Slashdot prior to taking this class.) Initially, the three of us generated a wide range of ideas to implement with Slashdot. However, some were not feasible within the scope of the project, and others ended up generating negative results or conflicting implications. We completed the project by frequently culling, readjusting, and coordinating the goals of our data work.
   </p>
   <p>
    Secondly, it’s best to be as systematic as possible with the ideas you do pursue to completion. Since A1 is a fairly open-ended project, we did not have a set procedure to follow. However, by coincidence, we found some consistent differences between the two Slashdot datasets we were working with. Since merging the datasets may have changed our results quite a bit, this discovery led us to split our analyses into two parts which (I hope) made our project more comprehensive at the end of the day.
   </p>
   <p>
    <break>
    </break>
   </p>
   <p>
    Proudness Factor:
   </p>
   <p>
    I am proud about how our group managed to make reasonable conjectures and inferences that built upon each other without referring to a particular theory or model for guidance. I rarely have a chance to approach data work without such guidance, nor did I have much past work on NLP + social interactions, so I was very impressed to see how, in a limited amount of time, we still managed to meld three people’s separate intuitions into a cohesive analysis.
   </p>
   <p>
    <break>
    </break>
   </p>
   <p>
    Time:
   </p>
   <p>
    As mentioned above, I had little past work on NLP + social interactions, so I spent a lot of time figuring out how to produce visualizations that make sense for this project. (A good portion of that time was also spent figuring out how to mechanically generate said visualizations in Python.) In a similar vein, I spent a long time figuring out how to formally describe and connect what we found.
   </p>
   <p>
    <break>
    </break>
   </p>
   <h3>
    ------------------------------------
   </h3>
  </div>
  <div style="text-indent: 2em;">
   <h3>
    Author: Kowe Kadoma (student)
   </h3>
   <h3>
    Vote Count: 0
   </h3>
   <p>
    One lesson I would like to pass on from my A1 experience is to be exploratory. It’s ok to modify the initial plan. My teammates and I had all these ideas about how to define and measure a bad comment. When we started looking into the data, we created all sorts of graphs- some of which we hadn’t anticipated when we were planning the experiment. I found a few of the results unexpected, and that was exciting.
   </p>
   <p>
    During this project, I was able to take my teammate’s code and modify it for my use. I usually have difficulty reading other people’s code and applying it to my own, so I’m proud that I could do so for the project. Creating the visualizations was the most time-consuming part of the project. I’m not too familiar with visualization in Python, so I spent several hours trying to arrange and rearrange the data frames to create several types of graphs. To overcome this problem, I used Excel to make the figures.
   </p>
   <h3>
    ------------------------------------
   </h3>
  </div>
 </div>
</div>