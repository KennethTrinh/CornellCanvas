<h1>
 Title: Progress Report for Project: Gab &amp; OSC gender
</h1>
<h3>
 Author: Breanna Green (student)
</h3>
<h3>
 Date: 2021-12-03T03:41:25.63971+11:00
</h3>
<h3>
 Category: Progress report for in-class comments (A5)
</h3>
<h3>
 Vote Count: 0
</h3>
<a href="https://static.us.edusercontent.com/files/o366gqU0tive5txqaARcoqc8">
 Progress_Report.docx"/&gt;
 <p>
  To review my original project proposal, I hoped to examine the role of the
  <i>
   perceived gender,
  </i>
  particularly for users who outwardly self-categorize as female. I used Gab.com data derived from Pushshift.io as my dataset, which contained posts from 2016 to late 2018 and was scraped monthly and pre-cleaned. To generate a usable dataset for these purposes, I hand-labeled the bio information for a sample of Gab users, looking for indications of ‘female’ or ‘male’ identifiers.
 </p>
 <p>
  <b>
   I originally hypothesized (with edits):
  </b>
 </p>
 <p>
  ·H.1: In comparison to users who OSC as male on Gab, less users will OSC as female.
 </p>
 <p>
  ·H.2: Those users that OSC as female will have a higher average score on the dual aspects Moral Foundations of harm and purity than both OSC males and randomly sampled users.
 </p>
 <p>
  ·H.3: Responses to OSC females will score higher in negative sentiment on average compared to OSC males.
 </p>
 <p>
  Given the size of the file, I narrowed this analysis to a small sample of users in each group, and plan to generate the results on the larger dataset once the code is fully written.
  <b>
   Therefore, for this update, I will focus on H.2 and H.3,
  </b>
  with results generated using LIWC and the Moral Foundations dictionary.
 </p>
 <p>
  <b>
   H.2:
  </b>
 </p>
 <figure>
  <image height="372" src="https://static.us.edusercontent.com/files/5OhvJcBN3qOEuLFfw8dqmG81" width="424"/>
 </figure>
 <p>
  In H.2, I indicated that OSC female users would have a higher score on the dual aspects of harm and purity when compared to both OSC male and control users. [For reference to the dictionary see
  <a href="https://moralfoundations.org/wp-content/uploads/files/downloads/moral%20foundations%20dictionary.dic">
   SOURCE
  </a>
  ; Virtue related words are positive, while Vice words are negative]. The visual above indicates that this is true for Harm overall, and PurityVirtue but not for PurityVice [OSC = female, OSCm = male, non_OSC = control].
 </p>
 <p>
  <b>
   H.3:
  </b>
 </p>
 <figure>
  <image height="359" src="https://static.us.edusercontent.com/files/Jl0paHd7QdqCGm7cUV0oktIS" width="460"/>
 </figure>
 <p>
  In H.3, I indicated that OSC female users would score higher on negative sentiment compared to OSC male. As shown in the visual above, that was not the case, which was an interesting result. The above scores were generated via LIWC. Both OSC female and male user scored higher on both positive and negative sentiment compared to the control group. OSC female users scored highest on positive emotion while OSC male users scored higher on negative sentiment.
 </p>
 <p>
  <b>
   Future tasks:
  </b>
 </p>
 <p>
  Unfortunately, given a lack of reply/comment data, I was unable to investigate interactions between OSC users and their audiences. Instead, I have implemented the Fighting Words analysis between each group, as well as conducted topic models. I am currently in the process of analyzing those results.
 </p>
 <p>
  As a simple visual, I generated wordclouds for both OSC female and male users.
 </p>
 <p>
  <b>
   OSC Female
  </b>
 </p>
 <figure>
  <image height="202" src="https://static.us.edusercontent.com/files/9WA3cykNDtqhdDoKbHFnfoZD" width="400"/>
 </figure>
 <p>
  <b>
   OSC Male
  </b>
 </p>
 <figure>
  <image 2em;"="" height="202&lt;/a&gt;&lt;/figure&gt;&lt;div style=" src="https://static.us.edusercontent.com/files/lljUH3QydZw8LnAegfmjk3XZ" text-indent:="" width="400"/>
  <h3>
   Author: Fede Bologna (she/her) (student)
  </h3>
  <h3>
   Vote Count: 0
  </h3>
  <p>
   I am very excited about this project and would like to hear more about the direction you envision it will take!
  </p>
  <p>
   Regarding H2, there is a specific pair of results that I find extremely interesting. OSC female users score higher in AuthorityVice but lower in AuthorityVirtue. I feel this finding might give insights on women empowerment in far-right communities. An hypothesis could be that OSC female users do not feel comfortable with assigning or prescribing values of authority themselves, but do have a clear idea of what authority is in the community. Therefore, they are able to identify transgressions from it. I also find incredibly valuable you finding on PurityVirtue and I would be curious to read posts that are assigned for PurityVice scores in order to better understand this phenomenon.
  </p>
  <p>
   As far as H3 is concerned, I think it would be interesting to run topic modeling on positive sentiment posts by OSC female users (I see that you mentioned you already performed topic modeling so maybe this suggestion is already outdated). In fact, I wonder if sentiment are connected to the kinds of topics OSC female users discuss, given also the fact that OSC male users posts are assigned the highest negative sentiment.
  </p>
  <p>
   The FightinWords clouds are also very salient: I specifically notice ‘thank’, ‘u’ and ‘please’ in the OSC female posts. Whereas dominant words in the OSC male posts are ‘fact’, ‘usa’, and’ think’. I wonder what the cleaning process for the posts consisted in: I wonder how results might changing when lemmatizing words and removing for stop words.
  </p>
  <p>
   In terms of potential future steps, I would be very curious to see the application of these questions to a larger dataset, so that your analysis could also capture shifts in sentiment over a longer period of time However that might get very time-consuming in terms of labeling for gender. I know there is a specific Twitter dataset that has been curated by the New York Times and contains such information - don’t know exactly where to find it, but I will ask in my lab!
  </p>
  <p>
   Another suggestion would be to train a classifier to recognize language on stereotypical depictions of womanhood. Or to use already-available classifiers on harmful language.
  </p>
  <p>
   Thank you for this project, happy to discuss in person! :)
  </p>
  <h3>
   ------------------------------------
  </h3>
  <div style="text-indent: 2em;">
   <h3>
    Author: Roz Thalken (student)
   </h3>
   <h3>
    Vote Count: 0
   </h3>
   <p>
    Hi Bre! This project is already so interesting and complicated! I’m glad to hear about what you’re working on (and it’s interesting in comparison to your project from our other class together). I admire how you’re digging into really difficult and socially/politically important problems.
   </p>
   <p>
    One of the most interesting parts of this project (to me) is that there can still be sexism and gender bias in a community where there’s already been self-selection (though this self selection could
    <i>
     also
    </i>
    intensify the likelihood of bias). Still, the idea that bias pervades in a setting where people already (presumptively) have a lot in common w/ political leanings is fascinating. I might be making assumptions about Gab users when responding to this though,  because I don’t know a lot about that community. I’d love to know more about how you’re handling the self-selection into this community, and how it compares to other communities. Are you suprised at what you’ve found so far // how do you think about analyzing gender bias in this sort of community?
   </p>
   <p>
    Methodologically, your data serves the purpose of your research questions and hypotheses. I’d love to know more about your process of identifying outward self-categorization in bios. I also wonder if gender terms (e.g. “man” and “woman” instead of “male” and “female”) might be more appropriate for this project, since it seems to be specifically about gender roles, which are socialized.
   </p>
   <p>
    From here, I’m also curious about how you’re handling the unbalanced class problem (which you note, in H1) while testing the next hypotheses. Do you balance classes before analyzing writing traits? If not, I wonder if the specificities of some of the people classified as OSC female might just have more of a chance to affect the results since there are fewer of them? Whereas the OSC male category might have enough data where individual differences aren’t as likely to affect results. I’m also wondering about this for the word clouds—and what the word clouds look like for the community as a whole.
   </p>
   <p>
    Especially given your current results, it seems like H2 is one of the main results you’ll probably focus on. For that reason, I wonder if you might rephrase it to distinguish it from your methods a bit? As a reader, I don’t know what “dual aspects Moral Foundations of harm and purity” means. This is a really specific/small thing, but I think making this a bit more interpretable when presenting the research idea might be useful.
   </p>
   <p>
    Finally, I think the connection between bios and posts is a really cool (and, I’m sure, painstaking to gather) idea. Is there other information you’ve grabbed from bios? Moving forward, if there are other pieces of information that a person uses to self-categorize, it could be interesting to pair that with gender info.
   </p>
   <p>
    Thank you for this report! Looking forward to discussing. Sorry that I’m always longwinded, but I really like your project :)
   </p>
   <h3>
    ------------------------------------
   </h3>
   <div style="text-indent: 2em;">
    <h3>
     Author: Prof. Lee (she/they) (admin)
    </h3>
    <h3>
     Vote Count: 0
    </h3>
    <p>
     Quick clarification q: what is the size of the OSC, OSCm, and non_OSC sets for the plots above?
    </p>
    <h3>
     ------------------------------------
    </h3>
    <div style="text-indent: 4em;">
     <h3>
      Author: Prof. Lee (she/they) (admin)
     </h3>
     <h3>
      Vote Count: 0
     </h3>
     <p>
      Related: I am guessing that the y-axis in the H2 plot is the score, averaged over OSCs (say).  If so, how is the score for a particular user computed?  For example: if they only made one post, is the score computed as the average score over the words in the post?  If the user makes two posts, are the scores for the two posts averaged, or are the two posts concatenated and treated as a single post, or are different posts treated as two different sample points?
     </p>
     <p>
      [thanks for providing the SOURCE link, by the way!]
     </p>
     <h3>
      ------------------------------------
     </h3>
    </div>
   </div>
  </div>
  <h3>
   ----------- REPLIES -----------
  </h3>
 </figure>
</a>