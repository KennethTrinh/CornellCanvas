<h1>
 Title: "Problem I'm having" megathread
</h1>
<h3>
 Author: Prof. Lee (she/they) (admin)
</h3>
<h3>
 Date: 2021-10-22T05:41:10.720372+11:00
</h3>
<h3>
 Category: Problem
</h3>
<h3>
 Vote Count: 1
</h3>
<document version="2.0">
 <paragraph>
  This is a place for you to post your "could anyone help me with?" questions as a comment!  (If it gets resolved, please mark it as resolved if the interface lets you.)
 </paragraph>
</document>
<h3>
 Author: Heather Zheng (student)
</h3>
<h3>
 Vote Count: 0
</h3>
<document version="2.0">
 <paragraph>
  Hi, I had a problem with how to find word innovation in the online forum. The method I am using is from the paper No country for old members: User lifecycle and linguistic change in online communities: “for the word never used before, used &gt;=10 times by multiple users talking about different products for a period of 6 months after first use. “ However, in terms of Reddit, some communities at the beginning several years only have a few hundreds post every month, but suddenly rise to ~10k one year later. I don’t think the word emerging here is called the word innovation, it is more likely to be caused by more posts. Currently, I am thinking about setting a threshold for initial word bases. But is there any better way?
 </paragraph>
</document>
<h3>
 ------------------------------------
</h3>
<h3>
 Author: Prof. Lee (she/they) (admin)
</h3>
<h3>
 Vote Count: 1
</h3>
<document version="2.0">
 <paragraph>
  Good observation!
  <break>
  </break>
  <break>
  </break>
  I can think of two possibilities off-hand:
 </paragraph>
 <paragraph>
  1. start looking for innovations for a community only when the community has reached a certain rate of posts over a period of some time (say, 3 months)
 </paragraph>
 <paragraph>
  2. Make the threshold not be absolutely fixed, but a function of volume.
 </paragraph>
</document>
<h3>
 ------------------------------------
</h3>
<h3>
 Author: Prof. Lee (she/they) (admin)
</h3>
<h3>
 Vote Count: 0
</h3>
<document version="2.0">
 <paragraph>
  Two projects  are reporting non-reasonable topics with topic models.  I myself have never found topic models to be so useful for my research and so have advised alternatives, but for those who know how to debug/come up with the magic incantation parameters/preprocessing steps, do you have any advice? Please see
  <link href="https://edstem.org/us/courses/8208/discussion/751710?comment=1843961"/>
  https://edstem.org/us/courses/8208/discussion/751710?comment=1843961 and
  <link href="https://edstem.org/us/courses/8208/discussion/752919?comment=1848146"/>
  https://edstem.org/us/courses/8208/discussion/752919?comment=1848146 :
  <break>
  </break>
  <break>
  </break>
 </paragraph>
 <paragraph>
  0: data social research study theory effects family differences analysis studies
  <break>
  </break>
  1: rockefeller social bulmer martin ruml ssrc research philanthropy council family
  <break>
  </break>
  2: martin social rockefeller ruml research bulmer philanthropy council foundations ssrc
  <break>
  </break>
  3: rockefeller social ruml martin bulmer philanthropy council research ssrc evidence
  <break>
  </break>
  4: rockefeller bulmer social martin research ruml foundations council ssrc sciences
  <break>
  </break>
  5: rockefeller social research ruml martin bulmer philanthropy foundations evidence fisher
  <break>
  </break>
  6: rockefeller ruml research bulmer social martin philanthropy ssrc council foundations
  <break>
  </break>
  7: social bulmer rockefeller martin research ruml ssrc sciences council philanthropy
  <break>
  </break>
  8: social rockefeller martin bulmer research ssrc ruml philanthropy council sciences
  <break>
  </break>
  9: rockefeller social bulmer research ruml martin philanthropy council ssrc evidence
 </paragraph>
 <paragraph>
 </paragraph>
 <paragraph>
 </paragraph>
 <paragraph>
  <break>
  </break>
 </paragraph>
 <list style="unordered">
  <list-item>
   <paragraph>
    <break>
    </break>
    “Neural deep agent generate game cluster”
   </paragraph>
  </list-item>
  <list-item>
   <paragraph>
    “Image neural sequence deep generate cluster”
   </paragraph>
  </list-item>
  <list-item>
   <paragraph>
    “Neural feature text generate event deep”
   </paragraph>
  </list-item>
  <list-item>
   <paragraph>
    “Feature decision approximate search image dynamic”
   </paragraph>
  </list-item>
  <list-item>
   <paragraph>
    “Measure generate stochastic estimate approximate”
   </paragraph>
  </list-item>
  <list-item>
   <paragraph>
    “Feature rule multi neural”
   </paragraph>
  </list-item>
  <list-item>
   <paragraph>
    “Neural policy plan feature generate decision”
   </paragraph>
  </list-item>
  <list-item>
   <paragraph>
    “Generate feature neural policy example”
   </paragraph>
  </list-item>
  <list-item>
   <paragraph>
    “Feature embed memory neural layer”
   </paragraph>
  </list-item>
  <list-item>
   <paragraph>
    “Feature generate estimate program”
   </paragraph>
  </list-item>
  <list-item>
   <paragraph>
    “Neural architecture generate feature text”
   </paragraph>
  </list-item>
  <list-item>
   <paragraph>
    “Feature neural input user game”
   </paragraph>
  </list-item>
  <list-item>
   <paragraph>
    “Cluster user feature depend tree”
   </paragraph>
  </list-item>
  <list-item>
   <paragraph>
    “Translate similar ctor graph neural text”
   </paragraph>
  </list-item>
  <list-item>
   <paragraph>
    “Neural feature topic classify”
   </paragraph>
  </list-item>
 </list>
 <paragraph>
 </paragraph>
</document>
<h3>
 ------------------------------------
</h3>
<h3>
 Author: Prof. Lee (she/they) (admin)
</h3>
<h3>
 Vote Count: 0
</h3>
<document version="2.0">
 <paragraph>
  I'm going to just give a reference to the following:
  <link href="http://users.umiacs.umd.edu/~jbg/docs/2014_book_chapter_care_and_feeding.pdf"/>
  http://users.umiacs.umd.edu/~jbg/docs/2014_book_chapter_care_and_feeding.pdf
 </paragraph>
 <paragraph>
  "Care and Feeding of Topic Models: Problems, Diagnostics, and Improvements."
 </paragraph>
</document>
<h3>
 ------------------------------------
</h3>
<h3>
 Author: Breanna Green (student)
</h3>
<h3>
 Vote Count: 0
</h3>
<document version="2.0">
 <paragraph>
  Is anyone particularly good at systematically viewing data from a huge file?
 </paragraph>
 <paragraph>
  In Python, I am reading in the file to a Pandas dataframe in small chunks. Not ALL the data of course! But just few days worth. My issue is that it takes up a lot of memory (even when chunked).
 </paragraph>
 <paragraph>
  I'm not sure the best way to do this, so if anyone has any idea how to handle this, it would be super helpful!
 </paragraph>
 <paragraph>
 </paragraph>
</document>
<h3>
 ------------------------------------
</h3>
<h3>
 Author: Fengyang Lin (student)
</h3>
<h3>
 Vote Count: 0
</h3>
<document version="2.0">
 <paragraph>
  Not specifically for viewing data, but I found a Python package similar to Pandas might be useful - GraphLab(
  <link href="https://github.com/apple/turicreate/"/>
  https://github.com/apple/turicreate/). The package uses distributed computation framework and is good at working with large-scale data.  Specifically, it has a data structure SFrame which is similar to pd.DataFrame. But I am not sure if it takes less memory than Pandas does, would want to check on that!
 </paragraph>
</document>
<h3>
 ------------------------------------
</h3>
<h3>
 Author: Prof. Lee (she/they) (admin)
</h3>
<h3>
 Vote Count: 0
</h3>
<document version="2.0">
 <paragraph>
  Hi, I can see several answers to this (quite reasonable) question, depending on the following: when you mention "viewing", do you literally mean that you are trying to spot check and visually read the data?  Or do you mean you mean computationally processing the data?
 </paragraph>
 <paragraph>
  If the former, a quick and dirty solution is to sample from the file.  Is it a text-based file, in which case one can pass it through command-line, sequentially-processing tools and randomly select items from it?
 </paragraph>
 <paragraph>
 </paragraph>
</document>
<h3>
 ------------------------------------
</h3>
<h3>
 Author: Celine Lee (student)
</h3>
<h3>
 Vote Count: 0
</h3>
<document version="2.0">
 <paragraph>
  I'm doing some token matching across code and natural language text in a StackOverflow answer, and found that there are some instances where as humans when we read, the tokens are clearly aligned or the same, but it's difficult to programmatically mark them as the same during token counting. (example below. 'layout' should map to 'setlayoutparams', 'layoutparams', and 'yourlayout' as well as to 'layout'. 'button' should also map to 'yourbutton'. )
 </paragraph>
 <paragraph>
  I'd like to be able to count these as shared tokens, but I'm not sure how to programmatically do so. (e.g. substring matching sounds like it could lead to implementation and tractability complications; word embeddings being a learned method also sounds like it could lead to undesired results.) Would anybody have any suggestions?
 </paragraph>
 <figure>
  <image height="1408.25" src="https://static.us.edusercontent.com/files/7xFRkgDfTbAhR103VRVoo2AS" width="655"/>
 </figure>
</document>
<h3>
 ------------------------------------
</h3>
<h3>
 Author: Prof. Lee (she/they) (admin)
</h3>
<h3>
 Vote Count: 0
</h3>
<document version="2.0">
 <paragraph>
  Honestly, I think I'd just do substring match of shorter string into longer string.  Maybe some semi-hashing trick like check-that-each-char-of-shorter-shows-up-in-longer, if necessary (if really necessary, precomputing "character count profiles")?
 </paragraph>
</document>
<h3>
 ------------------------------------
</h3>
<h3>
 Author: Prof. Lee (she/they) (admin)
</h3>
<h3>
 Vote Count: 0
</h3>
<document version="2.0">
 <paragraph>
  (just recording for posterity that Celine went with word embeddings)
 </paragraph>
</document>
<h3>
 ------------------------------------
</h3>
<h3>
 Author: Linda Wang (student)
</h3>
<h3>
 Vote Count: 0
</h3>
<document version="2.0">
 <paragraph>
  Does anyone know who the contact person(s) is (are) for ConvoKit? I've looked through the ConvoKit documentation, but, while I can find guidelines for how to report issues, I can't seem to find an email to send a report to. Thank you!
 </paragraph>
</document>
<h3>
 ------------------------------------
</h3>
<h3>
 Author: Prof. Lee (she/they) (admin)
</h3>
<h3>
 Vote Count: 1
</h3>
<document version="2.0">
 <paragraph>
  If you are comfortable using GitHub, you could file an issue here:
  <link href="https://github.com/CornellNLP/Cornell-Conversational-Analysis-Toolkit/issues"/>
  https://github.com/CornellNLP/Cornell-Conversational-Analysis-Toolkit/issues
  <break>
  </break>
  <break>
  </break>
  If you'd prefer email, I'd suggest contacting Jonathan P. Chang, Andrew Wang, and Cristian Danescu-Niculescu-Mizil (all in the same email, they are all (now) at Cornell), and you can cc: me!    You can get their email addresses from the author block of
  <link href="https://aclanthology.org/2020.sigdial-1.8.pdf"/>
  their ConvoKit paper.
  <break>
  </break>
 </paragraph>
 <paragraph>
 </paragraph>
</document>
<h3>
 ------------------------------------
</h3>
<h3>
 ----------- REPLIES -----------
</h3>