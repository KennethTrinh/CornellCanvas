<h1>
 Title: The little exercise for today (language model max-likelihood-estimation example)
</h1>
<h3>
 Author: Prof. Lee (she/they) (admin)
</h3>
<h3>
 Date: 2021-11-05T06:37:16.634167+11:00
</h3>
<h3>
 Category: Lecture
</h3>
<h3>
 Vote Count: 0
</h3>
<p>
 Recall from the blackboard (where $C_L$ is some normalization constant with factorials and stuff involving $L$ and the $S_i$'s that you can ignore and I can never remember):
</p>
<math>
 C_L\prod_{i} \phi_i^{S_i} + \lambda\left(\sum_k \phi_k - 1\right)
</math>
<p>
 Calculus tells us that if we're trying to find the arg-max, we should "set the derivative to zero and solve for the unknown".
</p>
<list style="number">
 <li>
  <p>
   What is the unknown, that is, what variable(s) should we take the derivative with respect to?  (Answer is below)
  </p>
 </li>
 <li>
  <p>
   Try solving for the unknown.
  </p>
 </li>
 <li>
  <p>
   Does using the
   <i>
    log
   </i>
   of the lefthand side make things easier? (Hint/motivation: you'll often see papers working with the log )
  </p>
 </li>
</list>
<p>
 (Answer to 1 above: The $\phi$ variables are the unknowns.  I find it easiest, in order to keep all the notation and variables straight, to use, for each
 <i>
  j
 </i>
 , :
</p>
<math>
 \frac{d}{d\phi_j}
</math>
<p>
 That is, use a different variable,
 <i>
  j
 </i>
 , than the index variable
 <i>
  i
 </i>
 for the product. )
</p>
<h3>
 ----------- REPLIES -----------
</h3>