<h1>
 Title: Overfitting the test set?
</h1>
<h3>
 Author: Anonymous
</h3>
<h3>
 Date: 2021-05-17T01:54:55.074448+10:00
</h3>
<h3>
 Category: General
</h3>
<h3>
 Vote Count: 1
</h3>
<p>
 Just had a look at the private leaderboard and was surprised to find out that this team "Overfit My Model" correctly predicted that they were overfitting to the public test set as they saw a huge drop in leaderboard position on the private test set. I've seen this in other kaggle competitions too - teams name themselves "Overfitting" and do well on the public leaderboard but when the private leaderboard results come out, they suffer a drop in the leaderboard position.
</p>
<p>
 How do these teams know that they are overfitting to the test set? They have a modest number of submissions too. And if they recognize that they're overfitting, what keeps them from not overfitting?
</p>
<div style="text-indent: 2em;">
 <h3>
  Author: Samar Khanna (staff)
 </h3>
 <h3>
  Vote Count: 2
 </h3>
 <p>
  I'm pretty sure teams who have "overfit" in their names are using the term jokingly. I doubt they do it because they
  <i>
   know
  </i>
  they are going to overfit the model.
 </p>
 <h3>
  ------------------------------------
 </h3>
</div>
<h3>
 ----------- REPLIES -----------
</h3>
<div style="text-indent: 2em;">
 <h3>
  Author: Artem Streltsov (staff)
 </h3>
 <h3>
  Vote Count: 0
 </h3>
 <p>
  Team ranked #2 on the creative task chose overfitting as their name and yet they jumped 10 ranks up on the private dataset. Your observation does not generalize. Generally, it is not hard to overfit to unseen data. You can do it even just by training on a single example. "Overfit my model" have submitted 15 times which is a lot. Good machine learning strategy and analysis of intermediate results needs at most 5 submissions. There is obviously some degree of overfitting to the public test set happening - which is very common for kaggle competitions.
 </p>
 <h3>
  ------------------------------------
 </h3>
</div>