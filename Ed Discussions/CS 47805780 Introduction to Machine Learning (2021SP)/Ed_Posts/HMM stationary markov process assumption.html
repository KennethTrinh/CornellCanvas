<h1>
 Title: HMM stationary markov process assumption
</h1>
<h3>
 Author: Anonymous
</h3>
<h3>
 Date: 2021-04-17T02:04:14.225019+10:00
</h3>
<h3>
 Category: Lectures
</h3>
<h3>
 Vote Count: 0
</h3>
<figure>
 <image height="450.2105263157895" src="https://static.us.edusercontent.com/files/UhsgmyQ0hVHJfDbs8OpcZ2QR" width="658"/>
</figure>
<p>
 What does the "stationary" Markov process assumption mean? Is it saying that, regardless of where in the sequence we are transitioning from a particular state (let's call it state A) to another particular state (let's call it state B), the transition probability from state A to state B will always be the same?
</p>
<h3>
 ----------- REPLIES -----------
</h3>
<div style="text-indent: 2em;">
 <h3>
  Author: Scott Bass (student)
 </h3>
 <h3>
  Vote Count: 0
 </h3>
 <p>
  Exactly. In a non-stationary problem, the transition probabilities could change over time such that $$P(S_{i} = s | S_{i-1} = s') \neq P(S_{j} = s | S_{j-1} = s')$$ for some $i \neq j$.
 </p>
 <p>
  For POS tagging, this could mean for example that the probability of
  <i>
   ART
  </i>
  following
  <i>
   V
  </i>
  early on in the word sequence is not equal to the probability that
  <i>
   ART
  </i>
  follows
  <i>
   V
  </i>
  later on in the sequence which would change how you calculate the predictions in Viterbi's Algorithm.
 </p>
 <h3>
  ------------------------------------
 </h3>
</div>