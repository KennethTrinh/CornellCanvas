<h1>
 Title: Confusion about error bound on learning algo for realizable setting
</h1>
<h3>
 Author: Anonymous
</h3>
<h3>
 Date: 2021-04-07T15:58:40.668744+10:00
</h3>
<h3>
 Category: Lectures
</h3>
<h3>
 Vote Count: 0
</h3>
<document version="2.0">
 <paragraph>
  So on slide 4 of the learning in realizable setting lecture, we prove that given a learned algorithm h_s (so it is consistent) on data set S, we have an error bound of |H|exp(-epsilon*m).  However the following slide says that this is the same bound that there EXISTS such a consistent hypothesis. Isn't the probability that our learned algorithm is one of the special algorithms that obey this bound always going to be lower than the probability that there exists some hypothesis?
 </paragraph>
</document>
<h3>
 ----------- REPLIES -----------
</h3>
<h3>
 Author: Kaishuo Cheng (staff)
</h3>
<h3>
 Vote Count: 0
</h3>
<document version="2.0">
 <paragraph>
  We are using a loose bound in slide 4. We have an inequality to go from our algorithm within bound to there eixsts an algorithm within bound. To calculate that, we have an "or" operator, which allows us to use the union bound and have |H|exp(-epsilon*m).
 </paragraph>
 <paragraph>
  Also please include a screenshot of the slide next time if you have a question on slide.
 </paragraph>
</document>
<h3>
 ------------------------------------
</h3>