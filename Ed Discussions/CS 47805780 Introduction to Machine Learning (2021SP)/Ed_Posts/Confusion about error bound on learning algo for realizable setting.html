<h1>
 Title: Confusion about error bound on learning algo for realizable setting
</h1>
<h3>
 Author: Anonymous
</h3>
<h3>
 Date: 2021-04-07T15:58:40.668744+10:00
</h3>
<h3>
 Category: Lectures
</h3>
<h3>
 Vote Count: 0
</h3>
<p>
 So on slide 4 of the learning in realizable setting lecture, we prove that given a learned algorithm h_s (so it is consistent) on data set S, we have an error bound of |H|exp(-epsilon*m).  However the following slide says that this is the same bound that there EXISTS such a consistent hypothesis. Isn't the probability that our learned algorithm is one of the special algorithms that obey this bound always going to be lower than the probability that there exists some hypothesis?
</p>
<h3>
 ----------- REPLIES -----------
</h3>
<div style="text-indent: 2em;">
 <h3>
  Author: Kaishuo Cheng (staff)
 </h3>
 <h3>
  Vote Count: 0
 </h3>
 <p>
  We are using a loose bound in slide 4. We have an inequality to go from our algorithm within bound to there eixsts an algorithm within bound. To calculate that, we have an "or" operator, which allows us to use the union bound and have |H|exp(-epsilon*m).
 </p>
 <p>
  Also please include a screenshot of the slide next time if you have a question on slide.
 </p>
 <h3>
  ------------------------------------
 </h3>
</div>