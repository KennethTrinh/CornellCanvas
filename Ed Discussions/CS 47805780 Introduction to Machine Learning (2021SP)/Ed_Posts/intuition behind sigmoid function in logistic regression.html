<h1>
 Title: intuition behind sigmoid function in logistic regression
</h1>
<h3>
 Author: Anonymous
</h3>
<h3>
 Date: 2021-03-25T23:43:02.106301+11:00
</h3>
<h3>
 Category: Lectures
</h3>
<h3>
 Vote Count: 0
</h3>
<figure>
 <image height="429" src="https://static.us.edusercontent.com/files/dK3gBQ62wMu84cpGTouZTeTE" width="621"/>
</figure>
<p>
 What is the intuition behind why logistic regression uses the sigmoid function of (w dot x_i) for the probability parameter in the bernoulli RV that models our conditional probability distribution? I understand that it squashes the value between 0 and 1 so that it can be a valid probability value, but beyond that I'm not sure how to think about it. Also, why do we use the dot product between w and x_i?
</p>
<h3>
 ----------- REPLIES -----------
</h3>
<div style="text-indent: 2em;">
 <h3>
  Author: Michael Noor (staff)
 </h3>
 <h3>
  Vote Count: 0
 </h3>
 <p>
  Basically the sigmoid is supposed to look roughly linear close to 0 and flatten out toward the ends; a lot of loss functions have very high punishment for incorrect predictions that were given with probability close to 0/1 so the sigmoid allows us to approach 0/1 as we get more confident in our prediction without every exactly equaling them. The dot product is just a similarity measure in much the same way we were using w for linear classification, where now we're using the actual value of that dot product to form a probability instead of simply using its sign to make a binary prediction.
 </p>
 <h3>
  ------------------------------------
 </h3>
</div>