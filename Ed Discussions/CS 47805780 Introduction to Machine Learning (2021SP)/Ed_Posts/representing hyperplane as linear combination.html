<h1>
 Title: representing hyperplane as linear combination
</h1>
<h3>
 Author: Anonymous
</h3>
<h3>
 Date: 2021-03-18T22:47:45.487096+11:00
</h3>
<h3>
 Category: Lectures
</h3>
<h3>
 Vote Count: 0
</h3>
<figure>
 <image height="308.021563342318" src="https://static.us.edusercontent.com/files/YSULM2wnJtxBubYtTFXEd33M" width="427.99999999999994"/>
</figure>
<p>
 We saw that the hyperplane output by the perceptron can always be expressed as a linear combination of the training data, where the alpha_j*y_j's (as in the dual representation) are the coefficients in this linear combination.
</p>
<p>
 Would it also be fair to say that we could express the hyperplane as a linear combination of the training data, where the w_i's (as in the primary representation) are the coefficients in a linear combination? Or am I understanding this incorrectly?
</p>
<h3>
 ----------- REPLIES -----------
</h3>
<div style="text-indent: 2em;">
 <h3>
  Author: Michael Noor (staff)
 </h3>
 <h3>
  Vote Count: 0
 </h3>
 <p>
  I'm not sure exactly what combination you're envisioning with the w_is as coefficients; w_i corresponds to a weight on feature i, not on training point i.
 </p>
 <h3>
  ------------------------------------
 </h3>
</div>