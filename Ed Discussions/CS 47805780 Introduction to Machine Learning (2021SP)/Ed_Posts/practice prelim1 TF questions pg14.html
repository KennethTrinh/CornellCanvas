<h1>
 Title: practice prelim1 T/F questions pg14
</h1>
<h3>
 Author: Anonymous
</h3>
<h3>
 Date: 2021-03-28T07:29:12.747721+11:00
</h3>
<h3>
 Category: Problem Sets
</h3>
<h3>
 Vote Count: 0
</h3>
<figure>
 <image height="87" src="https://static.us.edusercontent.com/files/Lir2ezbUvv9WTYk9bm7wRSfb" width="577"/>
</figure>
<p>
 I know that the first statement is false, but I don't quite intuitively understand why. It makes sense that, the more training data we have, the more accurate the classifier will be (the better it will perform on test data; aka the lower its prediction error), but I'm not exactly sure how that relates to overfitting. From what I understand, overfitting has to do with too closely fitting the training data, but that means that, it doesn't really matter
 <i>
  how much
 </i>
 data we have, but it matters more how closely we're trying to fit whatever amount of data we have. So I don't quite understand why a classifier trained on less training data is less likely to overfit.
</p>
<p>
 For the second statement, I know it's false, but I don't quite understand why it's false. I don't really intuitively understand how we can necessarily relate the amount of training data with the training error -- guidance would be appreciated!
</p>
<h3>
 ----------- REPLIES -----------
</h3>
<div style="text-indent: 2em;">
 <h3>
  Author: Atul Ganju (staff)
 </h3>
 <h3>
  Vote Count: 0
 </h3>
 <p>
  Overfitting relates to how the classifier trains on the training data vs the rest of the data. So, lets say we train a lot on almost all the data that we have. When we find new data, which does not necessarily have the same subtle patterns as the training data we used, our classifier, developed from the old data, would try and notice patterns that don't exist in the new dataset and may then classify certain vectors in the new dataset incorrectly.
 </p>
 <h3>
  ------------------------------------
 </h3>
</div>