<h1>
 Title: order of instances in randomized weighted majority algorithm
</h1>
<h3>
 Author: Anonymous
</h3>
<h3>
 Date: 2021-04-29T10:35:49.391519+10:00
</h3>
<h3>
 Category: Lectures
</h3>
<h3>
 Vote Count: 0
</h3>
<document version="2.0">
 <figure>
  <image height="442" src="https://static.us.edusercontent.com/files/3dXc0nWRmKShJHBGfXy3YoPC" width="644"/>
 </figure>
 <paragraph>
  Since the randomized weighted majority algorithm introduces randomness into the hypothesis it produces through predicting with probabilities for each class, does this mean that the order of the instances that the algorithm sees matters? Will different orders of instances produce different hypotheses?
 </paragraph>
 <paragraph>
  What about for the having and weighted majority algorithms? Does order of instances matter there?
 </paragraph>
</document>
<h3>
 Author: Michael Noor (staff)
</h3>
<h3>
 Vote Count: 0
</h3>
<document version="2.0">
 <paragraph>
  Can you clarify what you mean by instances?
 </paragraph>
</document>
<h3>
 ------------------------------------
</h3>
<h3>
 Author: Anonymous
</h3>
<h3>
 Vote Count: 0
</h3>
<document version="2.0">
 <paragraph>
  I mean each x_t that we see at time t
 </paragraph>
</document>
<h3>
 ------------------------------------
</h3>
<h3>
 Author: Michael Noor (staff)
</h3>
<h3>
 Vote Count: 0
</h3>
<document version="2.0">
 <paragraph>
  Thanks; could you also clarify which lecture this is in?
 </paragraph>
</document>
<h3>
 ------------------------------------
</h3>
<h3>
 Author: Anonymous
</h3>
<h3>
 Vote Count: 1
</h3>
<document version="2.0">
 <paragraph>
  In the online learning module, the lecture "no regret learning and randomized weighted majority algorithm"
 </paragraph>
</document>
<h3>
 ------------------------------------
</h3>
<h3>
 ----------- REPLIES -----------
</h3>
<h3>
 Author: Michael Noor (staff)
</h3>
<h3>
 Vote Count: 0
</h3>
<document version="2.0">
 <paragraph>
  The order of the xs can influence the hypotheses that happen during the training process but should not influence the final hypothesis; this is because of the way that weights are scaled down consistently. Does that make sense?
 </paragraph>
</document>
<h3>
 ------------------------------------
</h3>