<h1>
 Title: order of instances in randomized weighted majority algorithm
</h1>
<h3>
 Author: Anonymous
</h3>
<h3>
 Date: 2021-04-29T10:35:49.391519+10:00
</h3>
<h3>
 Category: Lectures
</h3>
<h3>
 Vote Count: 0
</h3>
<figure>
 <image height="442" src="https://static.us.edusercontent.com/files/3dXc0nWRmKShJHBGfXy3YoPC" width="644"/>
</figure>
<p>
 Since the randomized weighted majority algorithm introduces randomness into the hypothesis it produces through predicting with probabilities for each class, does this mean that the order of the instances that the algorithm sees matters? Will different orders of instances produce different hypotheses?
</p>
<p>
 What about for the having and weighted majority algorithms? Does order of instances matter there?
</p>
<div style="text-indent: 2em;">
 <h3>
  Author: Michael Noor (staff)
 </h3>
 <h3>
  Vote Count: 0
 </h3>
 <p>
  Can you clarify what you mean by instances?
 </p>
 <h3>
  ------------------------------------
 </h3>
 <div style="text-indent: 4em;">
  <h3>
   Author: Anonymous
  </h3>
  <h3>
   Vote Count: 0
  </h3>
  <p>
   I mean each x_t that we see at time t
  </p>
  <h3>
   ------------------------------------
  </h3>
  <div style="text-indent: 6em;">
   <h3>
    Author: Michael Noor (staff)
   </h3>
   <h3>
    Vote Count: 0
   </h3>
   <p>
    Thanks; could you also clarify which lecture this is in?
   </p>
   <h3>
    ------------------------------------
   </h3>
   <div style="text-indent: 8em;">
    <h3>
     Author: Anonymous
    </h3>
    <h3>
     Vote Count: 1
    </h3>
    <p>
     In the online learning module, the lecture "no regret learning and randomized weighted majority algorithm"
    </p>
    <h3>
     ------------------------------------
    </h3>
   </div>
  </div>
 </div>
</div>
<h3>
 ----------- REPLIES -----------
</h3>
<div style="text-indent: 2em;">
 <h3>
  Author: Michael Noor (staff)
 </h3>
 <h3>
  Vote Count: 0
 </h3>
 <p>
  The order of the xs can influence the hypotheses that happen during the training process but should not influence the final hypothesis; this is because of the way that weights are scaled down consistently. Does that make sense?
 </p>
 <h3>
  ------------------------------------
 </h3>
</div>