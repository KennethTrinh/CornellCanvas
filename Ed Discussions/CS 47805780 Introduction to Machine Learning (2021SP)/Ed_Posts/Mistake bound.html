<h1>
 Title: Mistake bound
</h1>
<h3>
 Author: Anonymous
</h3>
<h3>
 Date: 2021-04-26T06:57:54.267482+10:00
</h3>
<h3>
 Category: Lectures
</h3>
<h3>
 Vote Count: 0
</h3>
<document version="2.0">
 <paragraph>
  The slides say that the mistake bound is at least $log_2(n)$  for any alg since any alg can be forced to make at least $log_2(n)$ mistakes. Is this for any algorithm in general or is this specific to  1-d Threshold algorithms?
 </paragraph>
 <figure>
  <image height="473.00319488817894" src="https://static.us.edusercontent.com/files/VxVwCm2jjPnBJ43FfxhBgYYw" width="658"/>
 </figure>
</document>
<h3>
 ----------- REPLIES -----------
</h3>
<h3>
 Author: Oliver Leung (student)
</h3>
<h3>
 Vote Count: 0
</h3>
<document version="2.0">
 <paragraph>
  This is specific to the 1-D thresholds. For example, Perceptron has a mistake bound of $R^2/\gamma^2$.
 </paragraph>
</document>
<h3>
 ------------------------------------
</h3>