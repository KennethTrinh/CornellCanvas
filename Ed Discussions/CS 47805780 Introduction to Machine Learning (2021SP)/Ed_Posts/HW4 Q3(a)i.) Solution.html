<h1>
 Title: HW4 Q3(a)i.) Solution
</h1>
<h3>
 Author: Anonymous
</h3>
<h3>
 Date: 2021-04-26T13:00:41.49+10:00
</h3>
<h3>
 Category: Problem Sets
</h3>
<h3>
 Vote Count: 0
</h3>
<document version="2.0">
 <paragraph>
  In Q3(a), the setup is a fully connected network with a flattened input of size $D$, a hidden layer of size $D$, and output of size $C$.
 </paragraph>
 <paragraph>
  Why is the number of parameters from the input to the hidden layer
  <bold>
   with bias
  </bold>
  just $D^2$? I thought it would be $(D+1)D$, with $+ 1$ to account for weights going from the bias to each of the hidden layer nodes.
 </paragraph>
 <paragraph>
 </paragraph>
</document>
<h3>
 ----------- REPLIES -----------
</h3>
<h3>
 Author: Victor Butoi (staff)
</h3>
<h3>
 Vote Count: 0
</h3>
<document version="2.0">
 <paragraph>
  I think you are right, with a linear layer that goes from D to D, without bias is D^2 and with bias is D^2 + D. If you lost points on this please ping one of the TAs.
 </paragraph>
</document>
<h3>
 ------------------------------------
</h3>