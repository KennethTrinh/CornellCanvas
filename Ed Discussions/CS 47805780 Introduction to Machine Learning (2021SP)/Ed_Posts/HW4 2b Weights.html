<h1>
 Title: HW4 2b Weights
</h1>
<h3>
 Author: Anonymous
</h3>
<h3>
 Date: 2021-04-06T06:13:27.000639+10:00
</h3>
<h3>
 Category: Problem Sets
</h3>
<h3>
 Vote Count: 0
</h3>
<p>
 For this question, I am confused if we are constructing weights w
 <sub>
  0,1
 </sub>
 or w
 <sub>
  1,2
 </sub>
 or both w
 <sub>
  0,1
 </sub>
 and w
 <sub>
  1,2
 </sub>
 . Specifically, are we only concerned with the weights from the hidden layer to the output layer? Or are the input to hidden layer weights also important and something other than 1's.
</p>
<h3>
 ----------- REPLIES -----------
</h3>
<div style="text-indent: 2em;">
 <h3>
  Author: Donal Lowsley-Williams (student)
 </h3>
 <h3>
  Vote Count: 1
 </h3>
 <p>
  It is my understanding that we are constructing weights for all edges involved in the network. That is, edges from the input layer to the hidden layer as well as from the hidden layer to the output layer. All edge weight choices are important, and for this question, serve as a design choice (they are learned values). Those that go from the input layer to the hidden layer will influence the input vectors before they are passed through the activation function.
 </p>
 <h3>
  ------------------------------------
 </h3>
</div>