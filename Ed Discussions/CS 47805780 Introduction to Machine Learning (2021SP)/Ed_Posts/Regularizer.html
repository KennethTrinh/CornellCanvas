<h1>
 Title: Regularizer
</h1>
<h3>
 Author: Anonymous
</h3>
<h3>
 Date: 2021-03-29T07:23:50.806506+11:00
</h3>
<h3>
 Category: General
</h3>
<h3>
 Vote Count: 0
</h3>
<document version="2.0">
 <paragraph>
  Is the purpose of the regularizer in discriminative learning algorithms to select for the simplest w and thus avoid complex hypotheses that are likely to overfit the data?
 </paragraph>
 <paragraph>
  Or should we think of the regularizers like the L2 norm as just maximizing the functional margin squared?
 </paragraph>
 <paragraph>
 </paragraph>
</document>
<h3>
 ----------- REPLIES -----------
</h3>
<h3>
 Author: Justin Lee (staff)
</h3>
<h3>
 Vote Count: 1
</h3>
<document version="2.0">
 <paragraph>
  Yes. The regularization term is definitely one way to prevent data from choosing weight vectors that  produce overtly complex hypotheses.
 </paragraph>
 <paragraph>
  I'm not to sure about the second part because classifiers like the hard margin svm would maximize the functional margin regardless of the regularization term.
 </paragraph>
 <paragraph>
 </paragraph>
</document>
<h3>
 ------------------------------------
</h3>