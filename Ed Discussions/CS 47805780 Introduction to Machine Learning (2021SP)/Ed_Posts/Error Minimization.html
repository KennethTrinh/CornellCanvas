<h1>
 Title: Error Minimization
</h1>
<h3>
 Author: Anonymous
</h3>
<h3>
 Date: 2021-02-21T09:08:21.587177+11:00
</h3>
<h3>
 Category: Lectures
</h3>
<h3>
 Vote Count: 0
</h3>
<p>
 When picking a feature that minimizes error, why don't we maximize $-\text{Err}(S|A)$ instead of $\text{Err}(S)-\text{Err}(S|A)$? Since the first term is always constant?
</p>
<h3>
 ----------- REPLIES -----------
</h3>
<div style="text-indent: 2em;">
 <h3>
  Author: Haomiao Liu (staff)
 </h3>
 <h3>
  Vote Count: 2
 </h3>
 <p>
  Computationally they are the same, but the subtraction just makes it clearer as to how much improvement of performance I get for this additional branching out.
 </p>
 <h3>
  ------------------------------------
 </h3>
</div>